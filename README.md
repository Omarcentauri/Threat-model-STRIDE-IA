# Threat-model-STRIDE-IA

# ðŸ›¡ï¸ Kultur Threat Modeling Demo  
### _Modelos que predicen amenazas desde el diseÃ±o (STRIDE + PyTM + IA + GitHub Actions)_

Este repositorio demuestra cÃ³mo realizar **modelado de amenazas automatizado** desde el diseÃ±o usando:

- **PyTM** (OWASP)  
- **IA** para clasificaciÃ³n y priorizaciÃ³n (STRIDE)  
- **GitHub Actions** para ejecutar el anÃ¡lisis en cada Pull Request  

El objetivo de esta demo es mostrar cÃ³mo integrar **Threat Modeling as Code** y **AI-assisted risk analysis** dentro del ciclo de desarrollo.

---

## ðŸ“Œ Â¿QuÃ© es esto?

Este repo **no contiene cÃ³digo de aplicaciÃ³n real**.  
AquÃ­ modelamos el sistema Ãºnicamente desde el diseÃ±o, expresado como cÃ³digo Python usando PyTM.

Luego:

1. PyTM genera amenazas automÃ¡ticamente basadas en reglas internas.  
2. Una IA clasifica esas amenazas segÃºn STRIDE, su severidad y mitigaciÃ³n recomendada.  
3. GitHub Actions decide si el Pull Request puede mergearse o debe bloquearse.

ðŸ‘‰ Esto demuestra cÃ³mo llevar la seguridad **desde el diseÃ±o** directamente al pipeline de CI/CD.

---

## ðŸ§± Arquitectura del Repositorio

- .
- â”œâ”€â”€ tm_kultur.py # Modelo PyTM (Threat Model as Code)
- â”œâ”€â”€ threat_modeling/
- â”‚ â””â”€â”€ ai_enricher.py # IA para clasificaciÃ³n y priorizaciÃ³n
- â”œâ”€â”€ docs/
- â”‚ â””â”€â”€ basic_template.md # Plantilla para el reporte de PyTM
- â””â”€â”€ .github/
- â””â”€â”€ workflows/
- â””â”€â”€ threat_modeling.yml # Pipeline de GitHub Actions


---

## âš™ï¸ Â¿CÃ³mo funciona?

### 1ï¸âƒ£ Modelo de amenazas como cÃ³digo â€” PyTM

El archivo `tm_kultur.py` describe:

- Actores  
- Componentes  
- Datastores  
- Flujos de datos  
- Boundaries  

PyTM usa esta definiciÃ³n para generar:

- `tm/threats.md` â†’ Reporte tÃ©cnico de amenazas  
- `tm/dfd.png` â†’ Diagrama de flujo de datos  

> Estas amenazas NO estÃ¡n clasificadas bajo STRIDE aÃºn.

---

### 2ï¸âƒ£ Enriquecimiento con IA

El script `ai_enricher.py`:

- Lee `threats.md`  
- Clasifica cada amenaza bajo STRIDE  
- Asigna severidad (Low, Medium, High, Critical)  
- Genera mitigaciones  
- Produce un JSON final: `tm/threats_ai.json`  

Si existe al menos 1 amenaza crÃ­tica: 
critical_found = true
exit 1


âž¡ï¸ Esto **bloquea el Pull Request**.

---

### 3ï¸âƒ£ GitHub Actions â€” Pipeline automÃ¡tico

Cada Pull Request dispara el workflow:

1. **Generate PyTM Threat Report**  
2. **AI Threat Classification**

Artifacts disponibles:

- `pytm-output/` â†’ threats.md + dfd.png  
- `ai-output/` â†’ threats_ai.json  

Si la IA detecta amenazas crÃ­ticas, el pipeline falla y el PR queda bloqueado.

---

## ðŸ”§ ConfiguraciÃ³n requerida

### 1. Secrets en GitHub

Ir a:

**Settings â†’ Secrets and Variables â†’ Actions**

Crear:

| Secret Name      | Valor                         |
|------------------|--------------------------------|
| `AI_API_KEY`      | API key del proveedor de IA    |
| `AI_API_URL`      | Endpoint HTTP del modelo       |
| `AI_MODEL_NAME`   | (Opcional) Nombre del modelo   |

---

## ðŸ§ª Probar localmente (opcional)

### 

pip install pytm graphviz
python tm_kultur.py --report docs/basic_template.md > tm/threats.md
python tm_kultur.py --dfd | dot -Tpng -o tm/dfd.png

IA
export AI_API_KEY="..."
export AI_API_URL="..."
python threat_modeling/ai_enricher.py

## ðŸš€ Â¿QuÃ© demuestra esta demo?

âœ” Modelado de amenazas desde el diseÃ±o (Threat Modeling as Code).
âœ” AutomatizaciÃ³n con PyTM.
âœ” ClasificaciÃ³n STRIDE asistida por IA.
âœ” PriorizaciÃ³n de severidad.
âœ” Pipeline obligatorio que bloquea merges con amenazas crÃ­ticas.
âœ” DevSecOps real: seguridad en cada Pull Request.

## Â¿CÃ³mo usar este repositorio?

1. Realiza un cambio en tm_kultur.py.
2. Abre un Pull Request.
3. Observa cÃ³mo:
4. PyTM genera amenazas
5. IA las clasifica
6. El PR queda aprobado o bloqueado segÃºn el riesgo
